{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1445,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! /usr/bin/env python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please see EnronFraud_ML.docx for more details on the dataset and approches.\n",
    "\n",
    "Let's first import some libraries and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1446,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "from sklearn.metrics import *\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1447,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_clf(clf, features_test, labels_test, name):\n",
    "    '''\n",
    "    This function takes a classifier (clf), test features (features_test),\n",
    "    and test labels (labels_test) along with the method name (name) and \n",
    "    prints out some evaluation metrics. Note that you should run tester.py\n",
    "    for an extensive evaluation.\n",
    "    '''\n",
    "    print ('Accuracy for', name, 'is: ', clf.score(features_test, labels_test))\n",
    "    pred = clf.predict(features_test)\n",
    "    print ('precision for', name, 'is: ', precision_score(pred, labels_test))\n",
    "    print ('recall for' , name, 'is: ', recall_score(pred, labels_test))\n",
    "    \n",
    "def remove_from_list(orig_list, my_list):\n",
    "    '''\n",
    "    This function takes two lists and removes the items of the \n",
    "    second list(my_list) from the original list (orig_list)\n",
    "    '''\n",
    "    for item in my_list:\n",
    "        if item in orig_list:\n",
    "            orig_list.remove(item)\n",
    "    return orig_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1448,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I'll convert the dictionary to a pandas dataframe to do some feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1449,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poi</th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>other</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>salary</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>total_stock_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>METTS MARK</th>\n",
       "      <td>0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94299.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>585062.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>365788.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>807.0</td>\n",
       "      <td>1061827.0</td>\n",
       "      <td>585062.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAXTER JOHN C</th>\n",
       "      <td>0</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>1295738.0</td>\n",
       "      <td>-1386055.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6680544.0</td>\n",
       "      <td>11200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1586055.0</td>\n",
       "      <td>2660303.0</td>\n",
       "      <td>3942714.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>267102.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5634343.0</td>\n",
       "      <td>10623258.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELLIOTT STEVEN</th>\n",
       "      <td>0</td>\n",
       "      <td>350000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-400729.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4890344.0</td>\n",
       "      <td>78552.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12961.0</td>\n",
       "      <td>1788391.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170941.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211725.0</td>\n",
       "      <td>6678735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CORDES WILLIAM R</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>651850.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>386335.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.0</td>\n",
       "      <td>764.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1038185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HANNON KEVIN P</th>\n",
       "      <td>1</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3117011.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5538001.0</td>\n",
       "      <td>34039.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1617011.0</td>\n",
       "      <td>11350.0</td>\n",
       "      <td>853064.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>243293.0</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>288682.0</td>\n",
       "      <td>6391065.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  poi      bonus  deferral_payments  deferred_income  \\\n",
       "METTS MARK          0   600000.0                NaN              NaN   \n",
       "BAXTER JOHN C       0  1200000.0          1295738.0       -1386055.0   \n",
       "ELLIOTT STEVEN      0   350000.0                NaN        -400729.0   \n",
       "CORDES WILLIAM R    0        NaN                NaN              NaN   \n",
       "HANNON KEVIN P      1  1500000.0                NaN       -3117011.0   \n",
       "\n",
       "                  director_fees  exercised_stock_options  expenses  \\\n",
       "METTS MARK                  NaN                      NaN   94299.0   \n",
       "BAXTER JOHN C               NaN                6680544.0   11200.0   \n",
       "ELLIOTT STEVEN              NaN                4890344.0   78552.0   \n",
       "CORDES WILLIAM R            NaN                 651850.0       NaN   \n",
       "HANNON KEVIN P              NaN                5538001.0   34039.0   \n",
       "\n",
       "                  from_messages  from_poi_to_this_person  \\\n",
       "METTS MARK                 29.0                     38.0   \n",
       "BAXTER JOHN C               NaN                      NaN   \n",
       "ELLIOTT STEVEN              NaN                      NaN   \n",
       "CORDES WILLIAM R           12.0                     10.0   \n",
       "HANNON KEVIN P             32.0                     32.0   \n",
       "\n",
       "                  from_this_person_to_poi  loan_advances  long_term_incentive  \\\n",
       "METTS MARK                            1.0            NaN                  NaN   \n",
       "BAXTER JOHN C                         NaN            NaN            1586055.0   \n",
       "ELLIOTT STEVEN                        NaN            NaN                  NaN   \n",
       "CORDES WILLIAM R                      0.0            NaN                  NaN   \n",
       "HANNON KEVIN P                       21.0            NaN            1617011.0   \n",
       "\n",
       "                      other  restricted_stock  restricted_stock_deferred  \\\n",
       "METTS MARK           1740.0          585062.0                        NaN   \n",
       "BAXTER JOHN C     2660303.0         3942714.0                        NaN   \n",
       "ELLIOTT STEVEN      12961.0         1788391.0                        NaN   \n",
       "CORDES WILLIAM R        NaN          386335.0                        NaN   \n",
       "HANNON KEVIN P      11350.0          853064.0                        NaN   \n",
       "\n",
       "                    salary  shared_receipt_with_poi  to_messages  \\\n",
       "METTS MARK        365788.0                    702.0        807.0   \n",
       "BAXTER JOHN C     267102.0                      NaN          NaN   \n",
       "ELLIOTT STEVEN    170941.0                      NaN          NaN   \n",
       "CORDES WILLIAM R       NaN                     58.0        764.0   \n",
       "HANNON KEVIN P    243293.0                   1035.0       1045.0   \n",
       "\n",
       "                  total_payments  total_stock_value  \n",
       "METTS MARK             1061827.0           585062.0  \n",
       "BAXTER JOHN C          5634343.0         10623258.0  \n",
       "ELLIOTT STEVEN          211725.0          6678735.0  \n",
       "CORDES WILLIAM R             NaN          1038185.0  \n",
       "HANNON KEVIN P          288682.0          6391065.0  "
      ]
     },
     "execution_count": 1449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the dictionary to a pd dataframe\n",
    "df = pd.DataFrame.from_records(list(data_dict.values()))\n",
    "employees = pd.Series(list(data_dict.keys()))\n",
    "\n",
    "# set the index of df to be the employees series:\n",
    "df.set_index(employees, inplace=True)\n",
    "\n",
    "# Drop the email_address column because it has no use for us\n",
    "if 'email_address' in df:\n",
    "    del df['email_address']\n",
    "    \n",
    "### The first feature must be \"poi\". Make this happen\n",
    "poi = df['poi']\n",
    "df.drop(labels=['poi'], axis=1, inplace = True)\n",
    "df.insert(0, 'poi', poi)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Change the datatype to float. \n",
    "df = df.apply(lambda x: pd.to_numeric(x, errors='coerce')).copy() \n",
    "\n",
    "#convert booleans to int\n",
    "for c in df.columns:\n",
    "    if df[c].dtype == 'bool':\n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(df[c].values))\n",
    "        df[c] = lbl.transform(list(df[c].values))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the data a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1450,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 146 entries, METTS MARK to GLISAN JR BEN F\n",
      "Data columns (total 20 columns):\n",
      "poi                          146 non-null int64\n",
      "bonus                        82 non-null float64\n",
      "deferral_payments            39 non-null float64\n",
      "deferred_income              49 non-null float64\n",
      "director_fees                17 non-null float64\n",
      "exercised_stock_options      102 non-null float64\n",
      "expenses                     95 non-null float64\n",
      "from_messages                86 non-null float64\n",
      "from_poi_to_this_person      86 non-null float64\n",
      "from_this_person_to_poi      86 non-null float64\n",
      "loan_advances                4 non-null float64\n",
      "long_term_incentive          66 non-null float64\n",
      "other                        93 non-null float64\n",
      "restricted_stock             110 non-null float64\n",
      "restricted_stock_deferred    18 non-null float64\n",
      "salary                       95 non-null float64\n",
      "shared_receipt_with_poi      86 non-null float64\n",
      "to_messages                  86 non-null float64\n",
      "total_payments               125 non-null float64\n",
      "total_stock_value            126 non-null float64\n",
      "dtypes: float64(19), int64(1)\n",
      "memory usage: 24.0+ KB\n",
      "None\n",
      "                  column_name  missing_count\n",
      "19          total_stock_value             20\n",
      "18             total_payments             21\n",
      "13           restricted_stock             36\n",
      "5     exercised_stock_options             44\n",
      "15                     salary             51\n",
      "6                    expenses             51\n",
      "12                      other             53\n",
      "17                to_messages             60\n",
      "16    shared_receipt_with_poi             60\n",
      "7               from_messages             60\n",
      "8     from_poi_to_this_person             60\n",
      "9     from_this_person_to_poi             60\n",
      "1                       bonus             64\n",
      "11        long_term_incentive             80\n",
      "3             deferred_income             97\n",
      "2           deferral_payments            107\n",
      "14  restricted_stock_deferred            128\n",
      "4               director_fees            129\n",
      "10              loan_advances            142\n"
     ]
    }
   ],
   "source": [
    "#Get some basic information\n",
    "print df.info()\n",
    "missing = df.isnull().sum(axis=0).reset_index()\n",
    "# Get the number of missing values\n",
    "missing.columns = ['column_name', 'missing_count']\n",
    "missing = missing.ix[missing['missing_count']>0]\n",
    "missing = missing.sort_values(by='missing_count')\n",
    "print missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many poi do we have here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1451,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 1451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['poi'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at the employees name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1452,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'METTS MARK', u'BAXTER JOHN C', u'ELLIOTT STEVEN', u'CORDES WILLIAM R',\n",
       "       u'HANNON KEVIN P', u'MORDAUNT KRISTINA M', u'MEYER ROCKFORD G',\n",
       "       u'MCMAHON JEFFREY', u'HORTON STANLEY C', u'PIPER GREGORY F',\n",
       "       ...\n",
       "       u'SAVAGE FRANK', u'IZZO LAWRENCE L', u'TILNEY ELIZABETH A',\n",
       "       u'MARTIN AMANDA K', u'BUY RICHARD B', u'GRAMM WENDY L',\n",
       "       u'CAUSEY RICHARD A', u'TAYLOR MITCHELL S', u'DONAHUE JR JEFFREY M',\n",
       "       u'GLISAN JR BEN F'],\n",
       "      dtype='object', length=146)"
      ]
     },
     "execution_count": 1452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an employee named 'TOTAL' which contains the sum of all values from other employees. This is our outlier, let's remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1453,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.drop(['TOTAL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rescale the financial features. Note that this helps NB algorithm but apparently hurts DecisionTree a bit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1454,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    df = df.fillna(0)\n",
    "    features = list(df.columns.values)\n",
    "    other_features = ['poi', 'to_messages','shared_receipt_with_poi',\n",
    "                      'from_messages', 'from_poi_to_this_person', 'from_this_person_to_poi']\n",
    "    financial_features = remove_from_list(features, other_features)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    df[financial_features] = scaler.fit_transform(df[financial_features])\n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a few iterations, I realized that we need to create some new features to make a good models. Here I create two new features. 1) the portion of emails that a person sent to a poi, 2) the portion of emails that a person received from a poi. Intuitevely, these two must be very important. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1455,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Create new feature(s)\n",
    "df['to_poi_ratio'] = df['from_this_person_to_poi']/df['from_messages']\n",
    "df['from_poi_ratio'] = df['from_poi_to_this_person']/df['to_messages']\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data for compatibility with sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1456,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = df['poi'].values\n",
    "features = df.drop(['poi'], axis = 1).values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a first round of feature selection. Here I use SelectKBest to get the score of all features. I'll then drop the features that have score of 2 or smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1457,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 21.32789041   0.20970584  11.73269808   2.0893099   25.3801053\n",
      "   6.37461449   0.15877024   5.44668748   2.47052122   7.30140665\n",
      "  10.22290421   4.26357664   9.4807432    0.06447703  18.86179532\n",
      "   8.90382156   1.75169428   8.96781935  24.75252302  16.87387026\n",
      "   3.29382863]\n",
      "('Important features', array(['bonus', 'deferred_income', 'director_fees',\n",
      "       'exercised_stock_options', 'expenses', 'from_poi_to_this_person',\n",
      "       'from_this_person_to_poi', 'loan_advances', 'long_term_incentive',\n",
      "       'other', 'restricted_stock', 'salary', 'shared_receipt_with_poi',\n",
      "       'total_payments', 'total_stock_value', 'to_poi_ratio',\n",
      "       'from_poi_ratio'], dtype=object))\n",
      "('Number of important features', 17)\n",
      "('Number of dropped features: ', 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "# Create a SelectKBest object.\n",
    "select = SelectKBest(k=features.shape[1])\n",
    "features = select.fit_transform(features, labels)\n",
    "#Get and print the scores\n",
    "KBest_scores = select.scores_\n",
    "print KBest_scores\n",
    "# Find important features\n",
    "important_features = df.drop(['poi'], axis = 1).columns.values[np.where(KBest_scores > 2)]\n",
    "# Find features that will be dropped.\n",
    "dropped_features = df.drop(['poi'], axis = 1).columns.values[np.where(KBest_scores <= 2)]\n",
    "#Print some information\n",
    "print (\"Important features\", important_features)\n",
    "print (\"Number of important features\", len(important_features))\n",
    "print (\"Number of dropped features: \", len(dropped_features))\n",
    "#Drop less important features\n",
    "for feature in dropped_features:\n",
    "    df = df.drop(feature, axis =1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the dataframe back to a dictionary, and split them again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1458,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a list of column names:\n",
    "features_list = df.columns.values\n",
    "\n",
    "# create a dictionary from the dataframe\n",
    "data_dict = df.to_dict('index')\n",
    "### Store to my_dataset for easy export below.\n",
    "my_dataset = data_dict\n",
    "\n",
    "### Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "### Try a varity of classifiers\n",
    "from sklearn.cross_validation import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of assigning different names to my classifiers I put them into \"if clauses\". That way we can turn them on/off quickly.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1459,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy for', 'NB', 'is: ', 0.90909090909090906)\n",
      "('precision for', 'NB', 'is: ', 0.25)\n",
      "('recall for', 'NB', 'is: ', 0.5)\n"
     ]
    }
   ],
   "source": [
    "# NaiveBayes \n",
    "if True:\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(features_train, labels_train)\n",
    "    evaluate_clf(clf, features_test, labels_test, 'NB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1460,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "if False:\n",
    "    from sklearn import tree\n",
    "    param_grid = {\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'max_features': [5, 10, len(features_list)-1]\n",
    "            }\n",
    "    clf = GridSearchCV(tree.DecisionTreeClassifier(random_state = 42), param_grid)\n",
    "    clf = clf.fit(features_train, labels_train)\n",
    "    print \"Best estimator found by grid search for DecisionTree:\"\n",
    "    print clf.best_estimator_\n",
    "    evaluate_clf(clf, features_test, labels_test, 'DecisionTree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1461,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "if False:\n",
    "    from sklearn import svm\n",
    "    param_grid = {\n",
    "            'C': [1e3, 5e3, 1e4, 5e4, 1e5]\n",
    "            }\n",
    "    clf = GridSearchCV(svm.SVC(kernel='linear', class_weight='balanced'), param_grid)\n",
    "    clf = clf.fit(features_train, labels_train)\n",
    "    print \"Best estimator found by grid search for SVM:\"\n",
    "    print clf.best_estimator_\n",
    "    evaluate_clf(clf, features_test, labels_test, 'SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1462,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "if False:\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    param_grid = {\n",
    "            'n_estimators': [5, 10, 50]\n",
    "            }\n",
    "    clf = GridSearchCV(RandomForestClassifier(min_samples_split= 2, criterion='entropy', random_state=42), param_grid)\n",
    "    clf = clf.fit(features_train, labels_train)\n",
    "    print \"Best estimator found by grid search for RandomForest:\"\n",
    "    print clf.best_estimator_\n",
    "    evaluate_clf(clf, features_test, labels_test, 'RandomForest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1463,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Dump your classifier, dataset, and features_list so anyone can\n",
    "### check your results. You do not need to change anything below, but make sure\n",
    "### that the version of poi_id.py that you submit can be run on its own and\n",
    "### generates the necessary .pkl files for validating your results.\n",
    "\n",
    "dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
